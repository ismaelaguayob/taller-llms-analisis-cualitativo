---
title: "Taller"
subtitle: "Gemini para análisis cualitativo escalable en R"
author: "Ismael Aguayo y Exequiel Trujillo"
date: today
lang: en
fontsize: 14pt
format:
  html:
    code-fold: true
    toc: true
    toc-location: left
    toc-depth: 2
    toc-expand: 1
    toc-title: Contenidos
    number-sections: true
    theme: socialtec.scss
    code-link: true
    title-block-banner: true
bibliography: references.bib
csl: apa.csl
link-citations: true
editor_options: 
  chunk_output_type: console
---

## Antecedentes

### La revolución de la Inteligencia Artificial

-   Attention is all you need [@vaswani2017]: Artículo que crea la arquitectura transformer, que es la base de las IA actuales debido a su escalabilidad y eficiencia

-   Los grandes modelos de lenguaje (LLM por sus siglas en inglés) son modelos de Inteligencia Artificial entrenados en grandes volúmenes de datos, usualmente bajo la arquitectura de transformer, con la capacidad de comprender y generar texto para distintas tareas (traducción, programación, redacción, razonamiento, etc.)

-   30 de noviembre 2022: lanzamiento de ChatGPT. 100 millones de usuarios en un año.

-   Esto provocó un desarrollo acelerado de la IA en los últimos años:

    -   Áuge en la competencia y modelos open source: Claude, Gemini, Grok, Kimi-k2, Gemma, Gpt-Oss
    -   Múltiples aplicaciones: Vibe coding (Cursor, Windsurf), Ciencia (AlphaFold), Imágenes (MidJourney, NanoBanana), video (Veo3, Sora)
    -   Desarrollo de infraestructura clave: construcción de centros de datos y supercomputadores
    -   Avances en otras áreas como la robótica, la medicina, la neurociencia, etc.

### Herramientas de consumidor vs. herramientas de desarrollador

-   Dentro del mercado de la IA, existen distintos productos para distintas necesidades

-   Los servicios para los consumidores son los que comúnmente uno utiliza, los chatbot accesibles a través de las páginas web o aplicaciones de celular de ChatGpt o Gemini. Usualmente, tienen planes gratuitos y de pago.

![](images/chatgpt.jpg){fig-align="center"}

-   Por otro lado, están las plataformas para desarrolladores, comúnmente ofrecidas por las empresas a través de una Interfaz de Programación de Aplicaciones (API por sus siglas en inglés). A diferencia de los chatbots, las APIs cobran por cada llamada o mensaje enviado, y están diseñadas para poder desarrollar usos específicos de los LLM.

-   En este taller, utilizaremos este segundo enfoque, para aprovechar los beneficios que puede otorgar la Inteligencia Artificial, pero realizar los ajustes necesarios para mantener un flujo de investigación riguroso

### LLMs para análisis cualitativo

-   Anteriormente, la forma de utilizar *text-as-data* más común era a través de modelos más básicos, con una menor capacidad de comprender el contexto amplio. Por ejemplo, para identificar tipos de consumidores en un dataset de comentarios, se podía ejecutar un LDA o un STM para modelar los tópicos subyacentes.

-   Desde la arquitectura transformers, la capacidad de comprensión del contexto se disparó, con algoritmos como BertTopic que aprovechan este avance para realizar tópicos que capturen una mayor complejidad.

-   Sin embargo, los LLMs llevan esto a otro nivel, permitiendo realizar análisis profundo, cadenas de pensamiento, codificaciones y mapear redes entre actores. Softwares como Atlas.ti, ampliamente utilizado para el análisis cualitativo, ya integraron la codificación automática con GPT en sus útimas versiones.

-   La literatura reciente ha demostrado formas innovadoras de utilizar estas herramientas para diferentes técnicas de análisis cualitativo:

    -   Para realizar análisis de contenido [@bijker2024]

    -   Para mapear redes entre actores [@bro2025]

    -   Para realizar análisis de discurso [@zhang2025]

    -   Para teoría fundamentada [@yue2025]

-   La adaptación de los métodos y su validación es algo que está recién comenzando, y mientras que los estudios han destacado una buena correspondencia entre los códigos que realizan los LLM y los humanos, se han presentado grandes limitaciones y recomendaciones

-   **Limitaciones**

1.  Los códigos pueden ser más generales y omitir temas sensibles
2.  Los LLMs tienen el riesgo de alucinar (aunque esto ha reducido considerablemente en el último tiempo)
3.  Tienen una mayor dificultad de capturar tendencias generales

-   **Recomendaciones**

1.  Ingeniería de prompts precisa y bien pensada para el caso de uso específico
2.  Parametrización y selección correcta de modelos
3.  Colaboración y validación constante entre el investigador y el LLM, este es una herramienta útil, no reemplaza el trabajo.

## Contenidos de la parte práctica

-   Configuración de la sesión y preparaciones necesarias

-   Diseño y optimización de prompts, creación de criterios para evaluar los resultados de los LLMs

-   Comprensión básica de los principales parámetros de los modelos

-   Creación de una función para aplicar el análisis cualitativo y automatización de esta a lo largo de un dataframe

-   Análisis de la información obtenida

## Configuración de la sesión

```{r}
pacman::p_load(datamedios, gemini.R, dplyr, ggplot2, dotenv, purrr, jsonlite, flextable, GT) # Cargamos paquetes necesarios
options(scipen = 999) # Desactivamos notación científica
rm(list = ls()) # Limpiamos entorno de trabajo
```

## Procesamiento y carga de los datos

Nota: Por si acaso alguien tiene algún error inesperado para utilizar datamedios, preparemos un csv con la data ya extraída para que lo utilicen.

Cargamos los datos del paquete datamedios (<https://exetrujillo.github.io/datamedios/>).

```{r}

datos <- datamedios::extraer_noticias_fecha("inteligencia artificial", "2025-11-1", "2025-11-25")

```

Limpiamos los datos y seleccionamos las columnas de interés.

```{r}
datos <- datamedios::limpieza_notas(datos, sinonimos= c("IA", "chat gpt", "openai", "chatbot", "chatgpt"))

datos_filtrados <- datos %>%
    select(titulo, contenido_limpio, fecha, medio, url)
```

## Explorar data

```{r}
datamedios::grafico_notas_fecha(datos_filtrados, "Inteligencia artificial", tema = "dark")
```

Seleccionamos una submuestra de 20 noticias para reducir el tiempo de procesamiento de los análisis.

```{r}
set.seed(123)

noticias_muestra <- slice_sample(datos_filtrados, n=20)
```

Exploramos el dataframe de noticias.

```{r}

head(noticias_muestra)
```

## Configuramos Gemini

Nota: Manejar mejor la API key con .Renviron en vez de .env.

```{r}

google_api <- Sys.getenv("GEMINI_API_KEY")
setAPI(google_api) # check https://makersuite.google.com/app/apikey
gemini("¿Cuál es la diferencia entre la inteligencia artificial y la inteligencia artesanal? Responde en una línea")

```

```{r}
# Podemos hacer una configuración básica de gemini para el caso que queramos.

# En model se pueden usar varios para respuesta de texto, como "gemini-2.5-pro", "gemini-2.5-flash", "gemini-2.5-flash-lite", etc.
# Pueden revisar el listado completo en https://ai.google.dev/gemini-api/docs/models
g_model = "2.5-flash-lite"

# Podemos elegir también la temperatura para el modelo. Apunta a la objetividad-creatividad permitida en las respuestas.
# Números más cercanos a cero serían más "objetivos" y números más cercanos a dos serían más "creativos" (y propensos a alucinaciones).
g_temperature = 0.7

# También pdoemos setear una semilla para hacer los resultados más reproducibles aunque no podemos asegurarlo completamente
g_seed = 42

# Los siguientes recomendamos no cambiarlos para pruebas básicas
# maxOutputTokens = 8192
# topK = 40
# topP = 0.95
# timeout = 60

```

## 7. Prompts

En estricto rigor, gemini no permite que le pasemos instrucciones de sistema, petición de texto y estructuras de respuesta por separado. Nosotros en este caso los separamos en objetos distintos solo para hacerlo más modificable.

```{r}
system_prompt <- "Eres un científico social experto en análisis cualitativo con formación interdisciplinaria en sociología, antropología, ciencias políticas y ciencias de la comunicación. Tienes amplia experiencia en investigación de medios, análisis de discurso, estudios culturales y semiótica social. Posees la capacidad de examinar contenido mediático desde múltiples perspectivas teóricas, identificando marcos narrativos e interpretativos, agendas mediáticas, construcciones simbólicas y procesos de significación. Mantienes una perspectiva académica rigurosa y pensamiento crítico interdisciplinario."

prompt_instruccion <- "Analiza la siguiente noticia relacionada con inteligencia artificial desde una perspectiva de ciencias sociales y comunicación. Tu análisis debe ser profundo y reflexivo, examinando tanto el contenido explícito como los elementos implícitos y simbólicos.

Requisitos para el análisis:

- Determina el rol específico que cumple la IA en la noticia: ¿es el tema central, un elemento secundario, o apenas se menciona?
- Evalúa la centralidad de la IA en la narrativa y su relevancia real para el contenido
- Identifica orientaciones tecnofóbicas o tecnofílicas en el tratamiento informativo
- Examina cómo se representa la IA: sus capacidades, limitaciones, riesgos o beneficios
- Analiza los marcos interpretativos y narrativos utilizados para contextualizar la tecnología
- Detecta sesgos, omisiones o énfasis particulares en la construcción del discurso sobre IA
- Considera las implicaciones sociales, económicas o éticas planteadas
- Identifica actores sociales mencionados y sus posiciones respecto a la IA
- Evalúa qué perspectivas están presentes o ausentes en el debate
- Genera keywords conceptuales que capturen la esencia sociológica del contenido
- Proporciona un resumen analítico que sintetice los hallazgos principales

Mantén un enfoque crítico y académico, fundamentando tus observaciones en el contenido analizado."

json_estructura <- 'Responde exclusivamente en formato JSON válido. Tu respuesta debe ser ÚNICAMENTE así, comenzando con "{" y terminando con "}". 

** NO AGREGUES BLOQUES DE CÓDIGO EN TU RESPUESTA (de esas que tienen este caracter `)**

Consideraciones:
  - Las keywords deben ser 5, ir en minúsculas y si se componen de más de una palabra llevan espacios entre ellas.
  . Deben ser 5 actores principales, si no existe alguno entrega el campo igualmente con NULL.
  - Label: Máximo 3 palabras.

Estructura:

{
  "keywords": ["palabra1", "palabra2", "palabra3"],
  "orientacion_tecnologica": "tecnofobia|tecnofilia|neutralidad",
  "centralidad_ia": "alta|media|baja",
  "actores_principales": [
    {
      "nombre": "nombre_del_actor",
      "rol_respecto_ia": "descripción_breve_de_su_posición_o_relación_con_ia"
    }
  ],
  "analisis": "Análisis conciso en 2-3 oraciones que sintetice los hallazgos más relevantes del enfoque sociológico y comunicacional.",
  "label": "etiqueta_descriptiva_de_la_noticia"
})
'
```

## 9. Función para crear promt

```{r}
# Función 1: Crear prompt completo con contexto
crear_prompt_completo <- function(fila_noticia) {
  # Extraer información de la fila
  titulo <- fila_noticia$titulo
  contenido <- fila_noticia$contenido_limpio
  fecha <- fila_noticia$fecha
  
  # Crear contexto de la noticia
  contexto_noticia <- paste0(
    "# **Para responder básate únicamente en el contenido de la noticia a analizar.** \n",
    "CONTEXTO DE LA NOTICIA:\n",
    "Título: ", titulo, "\n",
    "Fecha: ", fecha, "\n\n",
    "CONTENIDO:\n", contenido
  )
  
  # Combinar todos los elementos del prompt
  prompt_final <- paste(
    system_prompt,
    "\n\n",
    prompt_instruccion,
    "\n\n",
    contexto_noticia,
    "\n\n",
    json_estructura,
    sep = ""
  )
  
  return(prompt_final)
}

prompt_example <- crear_prompt_completo(noticias_muestra[5,])
example <- gemini(
  prompt_example,
  model = g_model,
  temperature = g_temperature,
  seed = g_seed
)
```

## 10. Iteración guardando en una lista

Nota: Agregar try_catch para capturar errores.

```{r}
lista_respuestas <- list()

for (i in 1:nrow(noticias_muestra)){
  noticia <- noticias_muestra[i,]
  prompt <- crear_prompt_completo(noticia)

  analisis <- gemini(
  prompt,
  model = g_model,
  temperature = g_temperature,
  seed = g_seed
)

  lista_respuestas <- append(lista_respuestas, analisis)
  Sys.sleep(5)
}
```

## 11. Limpieza y aplanamiento

```{r}
lista_proc <- lapply(lista_respuestas, function(elemento) {
  texto_sucio <- elemento
  texto_limpio <- str_trim(str_remove_all(texto_sucio, "^```json|```$"))

  objeto_r <- fromJSON(texto_limpio, flatten = TRUE)
  
  return(objeto_r)
})

```

```{r}
aplanar_elemento <- function(elemento) {
  data.frame(
    # Vectores simples
    keywords = paste(elemento$keywords, collapse = "; "),
    orientacion_tecnologica = elemento$orientacion_tecnologica,
    centralidad_ia = elemento$centralidad_ia,
    label = elemento$label,
    analisis = elemento$analisis,
    
    # Información de actores (concatenamos todo)
    actores_nombres = paste(elemento$actores_principales$nombre, collapse = "; "),
    actores_roles = paste(elemento$actores_principales$rol_respecto_ia, collapse = "; "),
    
    stringsAsFactors = FALSE
  )
}

# Aplicar a todos los elementos
df_opcion1 <- purrr::map_dfr(lista_proc, aplanar_elemento)
```

```{r}
datos_unificados <- bind_cols(noticias_muestra, df_opcion1)
```

```{r}
library(DT)

datatable(datos_unificados,
  options = list(
    columnDefs = list(
      list(
        # Aplicar a las columnas 3 y 5
        targets = c(2, 4), 
        render = JS(
          "function(data, type, row, meta) {",
          "  return type === 'display' && data.length > 50 ?",
          "    '<span title=\"' + data + '\">' + data.substr(0, 50) + '...</span>' : data;",
          "}")
      )
    )
  )
)
```

```{r}
write.csv(datos_unificados, "datos.csv")


```